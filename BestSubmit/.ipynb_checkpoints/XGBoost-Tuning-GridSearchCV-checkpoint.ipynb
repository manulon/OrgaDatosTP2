{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpieza del dataset como en TP1\n",
    "\n",
    "oportunidades = pd.read_csv(\"Train_TP2_Datos_2020-2C.csv\")\n",
    "oportunidades['Account_Created_Date'] = pd.to_datetime(oportunidades['Account_Created_Date'])\n",
    "oportunidades['Opportunity_Created_Date'] = pd.to_datetime(oportunidades['Opportunity_Created_Date'])\n",
    "oportunidades['Quote_Expiry_Date'] = pd.to_datetime(oportunidades['Quote_Expiry_Date'])\n",
    "oportunidades['Last_Modified_Date'] = pd.to_datetime(oportunidades['Last_Modified_Date'])\n",
    "oportunidades['Planned_Delivery_Start_Date'] = pd.to_datetime(oportunidades['Planned_Delivery_Start_Date'])\n",
    "oportunidades['Planned_Delivery_End_Date'] = pd.to_datetime(oportunidades['Planned_Delivery_End_Date'])\n",
    "oportunidades_japon = (oportunidades.loc[oportunidades['Region'] == 'Japan'])\n",
    "oportunidades = (oportunidades.loc[oportunidades['Region'] != 'Japan'])\n",
    "#oportunidades_japon = oportunidades_japon.iloc[:,:3]\n",
    "oportunidades_japon['Territory'] = oportunidades_japon['Territory'].replace({'None':'Japan'})\n",
    "oportunidades = pd.concat([oportunidades, oportunidades_japon], axis=0)\n",
    "oportunidades['Region'] = oportunidades['Region'].replace({'Japan':'APAC', 'Middle East':'EMEA'})\n",
    "oportunidades[oportunidades.select_dtypes(['object']).columns] = oportunidades.select_dtypes(['object']).apply(lambda x: x.astype('category'))\n",
    "oportunidades = oportunidades.loc[oportunidades['Territory'] != 'None']\n",
    "oportunidades['Conversion_Moneda'] = oportunidades['ASP'] / oportunidades['ASP_(converted)']\n",
    "oportunidades['Total_Amount'] = oportunidades['Total_Amount'] / oportunidades['Conversion_Moneda']\n",
    "oportunidades['Total_Taxable_Amount'] = oportunidades['Total_Taxable_Amount'] / oportunidades['Conversion_Moneda']\n",
    "oportunidades = oportunidades.dropna()\n",
    "oportunidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Añadimos la columna binaria de si es aprobada o no.\n",
    "\n",
    "filtro_terminos_entrega = oportunidades['Pricing, Delivery_Terms_Quote_Appr']\\\n",
    "     == oportunidades['Pricing, Delivery_Terms_Approved']\n",
    "\n",
    "filtro_codigo_burocratico = oportunidades['Bureaucratic_Code_0_Approval']\\\n",
    "     == oportunidades['Bureaucratic_Code_0_Approved']\n",
    "\n",
    "oportunidades = oportunidades.drop(['Pricing, Delivery_Terms_Quote_Appr'\\\n",
    "    ,'Pricing, Delivery_Terms_Approved', 'Bureaucratic_Code_0_Approval'\\\n",
    "        , 'Bureaucratic_Code_0_Approved', 'Submitted_for_Approval'], axis = 'columns')\n",
    "\n",
    "oportunidades_posibles = (filtro_terminos_entrega & filtro_codigo_burocratico)\n",
    "\n",
    "oportunidades.insert(3,'Es_Oportunidad_Posible', oportunidades_posibles)\n",
    "\n",
    "oportunidades['Es_Oportunidad_Posible'] = oportunidades['Es_Oportunidad_Posible'].replace(\n",
    "    {True:1, False:0})\n",
    "oportunidades.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding de los vendedores con mean encoding respecto del total amount.\n",
    "encoding_owners = oportunidades.groupby('Opportunity_Owner').agg({'Total_Amount':'mean'})\n",
    "encoding_owners.columns = ['Encoding_Vendedor']\n",
    "encoding_owners = encoding_owners.reset_index()\n",
    "oportunidades = oportunidades.merge(encoding_owners, how='inner', on='Opportunity_Owner')\n",
    "oportunidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding de los territorios en base al total amount\n",
    "encoding_territory = oportunidades.groupby('Territory').agg({'Total_Amount' : 'mean'})\n",
    "encoding_territory.columns = ['Encoding_Territorio']\n",
    "encoding_territory = encoding_territory.reset_index()\n",
    "oportunidades = oportunidades.merge(encoding_territory, how='inner', on='Territory')\n",
    "oportunidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding de las regiones en base al total amount\n",
    "encoding_region = oportunidades.groupby('Region').agg({'Total_Amount' : 'mean'})\n",
    "encoding_region.columns = ['Encoding_Region']\n",
    "encoding_region = encoding_region.reset_index()\n",
    "oportunidades = oportunidades.merge(encoding_region, how='inner', on='Region')\n",
    "oportunidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding del tipo de moneda en base al mean del ASP\n",
    "encoding_moneda = oportunidades.groupby('Total_Amount_Currency').agg({'ASP' : 'mean'})\n",
    "encoding_moneda.columns = ['Encoding_Moneda']\n",
    "encoding_moneda = encoding_moneda.reset_index()\n",
    "oportunidades = oportunidades.merge(encoding_moneda, how='inner', on='Total_Amount_Currency')\n",
    "oportunidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding del Bureaucratic_Code en base a Dummies\n",
    "oportunidades = pd.concat([oportunidades, pd.get_dummies(oportunidades['Bureaucratic_Code'])], axis='columns')\n",
    "oportunidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding del Billing Country en base a mean de Total_Amount.\n",
    "encoding_bill_c = oportunidades.groupby('Billing_Country').agg({'Total_Amount' : 'mean'})\n",
    "encoding_bill_c.columns = ['Encoding_Billing_Country']\n",
    "encoding_bill_c = encoding_bill_c.reset_index()\n",
    "oportunidades = oportunidades.merge(encoding_bill_c, how='inner', on='Billing_Country')\n",
    "oportunidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding del Product_Family en base a mean de Total_Amount.\n",
    "encoding_product_family = oportunidades.groupby('Product_Family').agg({'Total_Amount' : 'mean'})\n",
    "encoding_product_family.columns = ['Encoding_Prod_Family']\n",
    "encoding_product_family = encoding_product_family.reset_index()\n",
    "oportunidades = oportunidades.merge(encoding_product_family, how='inner', on='Product_Family')\n",
    "oportunidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding con Dummies de Account_Type\n",
    "\n",
    "oportunidades = pd.concat([oportunidades, pd.get_dummies(oportunidades['Account_Type'])],axis='columns')\n",
    "oportunidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Encoding de Delivery Terms en base a Dummies\n",
    "oportunidades = pd.concat([oportunidades,pd.get_dummies(oportunidades['Delivery_Terms'])],axis='columns')\n",
    "oportunidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos el año de creación de la oportunidad como columna.\n",
    "oportunidades['Opportunity_Created_Year'] = oportunidades['Opportunity_Created_Date'].dt.year\n",
    "oportunidades['Opportunity_Created_Month'] = oportunidades['Opportunity_Created_Date'].dt.month\n",
    "oportunidades['Opportunity_Created_Month'] = oportunidades['Opportunity_Created_Month'].replace({1:'01',2:'02',3:'03',4:'04',5:'05',6:'06',7:'07',8:'08',9:'09'})\n",
    "oportunidades['Año_Por_Mes'] = (oportunidades['Opportunity_Created_Year'].astype(str) + \\\n",
    "    oportunidades['Opportunity_Created_Month'].astype(str)).astype(int)\n",
    "oportunidades['Año_Por_Mes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Una vez que tenemos el dataset limpio como en el TP1, iniciamos con el uso de XGBoost como algoritmo de ML.\n",
    "\n",
    "y_train = oportunidades['Stage']\n",
    "oportunidades = oportunidades.loc[(oportunidades['Stage'] == 'Closed Won') | (oportunidades['Stage'] == 'Closed Lost')]\n",
    "oportunidades['Stage'] = oportunidades['Stage'].replace({'Closed Won': 1, 'Closed Lost': 0})\n",
    "std_deviation_amounts = oportunidades.groupby('Opportunity_ID').agg({'Total_Amount':'std', 'Total_Taxable_Amount':'std',\\\n",
    "                                                                    'TRF':'std'})\n",
    "std_deviation_amounts.columns = ['Total_Amount_Std','Total_Tax_Amount_Std', 'TRF_Std']\n",
    "std_deviation_amounts = std_deviation_amounts.reset_index()\n",
    "\n",
    "#Solo usamos Bureau_Code_ 0,1,2,4,5 porque son los que tiene el set de test.\n",
    "x_train = oportunidades.groupby('Opportunity_ID').agg({'Año_Por_Mes' : 'mean',\\\n",
    "                                                      'Encoding_Moneda':'mean', 'Total_Amount': 'sum',\\\n",
    "                                                      'Total_Taxable_Amount':'mean', 'Encoding_Region':'mean',\\\n",
    "                                                      'Encoding_Territorio':'mean','Encoding_Vendedor':'mean',\\\n",
    "                                                      'Es_Oportunidad_Posible':'mean','Stage':'max', 'TRF':'mean',\n",
    "                                                      'Bureaucratic_Code_0':'mean','Bureaucratic_Code_1':'mean',\\\n",
    "                                                      'Bureaucratic_Code_2':'mean','Bureaucratic_Code_4':'mean',\n",
    "                                                      'Bureaucratic_Code_5':'mean', 'Encoding_Billing_Country':'mean',\\\n",
    "                                                      'Delivery_Terms_0':'mean','Delivery_Terms_1':'mean','Delivery_Terms_2':'mean',\\\n",
    "                                                      'Delivery_Terms_3':'mean','Delivery_Terms_4':'mean','Delivery_Terms_5':'mean',\\\n",
    "                                                      'Delivery_Terms_6':'mean','Delivery_Terms_7':'mean','Delivery_Terms_8':'mean',\n",
    "                                                      'Encoding_Prod_Family':'mean','Account_Type_0':'mean','Account_Type_1':'mean',\\\n",
    "                                                      'Account_Type_2':'mean','Account_Type_4':'mean', 'Account_Type_5':'mean'})\n",
    "x_train = x_train.reset_index()\n",
    "x_train = x_train.merge(std_deviation_amounts, on='Opportunity_ID', how='inner')\n",
    "x_train = x_train.set_index('Opportunity_ID')\n",
    "y_train = x_train['Stage']\n",
    "x_train = x_train.drop('Stage', axis='columns')\n",
    "x_train['Total_Amount_Std'] = x_train['Total_Amount_Std'].replace({np.nan:0})\n",
    "x_train['Total_Tax_Amount_Std'] = x_train['Total_Tax_Amount_Std'].replace({np.nan:0})\n",
    "x_train['Diferencia_Amounts'] = x_train['Total_Amount'] - x_train['Total_Taxable_Amount']\n",
    "x_train['TRF_Std'] = x_train['TRF_Std'].replace({np.nan:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Division del set de test y train:\n",
    "\n",
    "division_x_train, division_x_test, division_y_train, division_y_test = train_test_split(x_train, y_train, test_size = 0.3,\\\n",
    "                                                                                       random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning de Hiper parametros con GridSearchCV\n",
    "\n",
    "model = GridSearchCV(xgb.XGBRegressor(objective ='binary:logistic', n_estimators = 450, eval_metric = 'logloss'), {\n",
    "    'min_child_weight': [0.3,1,3,6],\n",
    "    'lambda': [0,1,2],\n",
    "    'learning_rate' : np.arange(0.01, 0.2, 0.005),\n",
    "    'colsample_bytree' : np.arange(0.5,1,0.1),\n",
    "    #'alpha' : [0.001,0.01,0.1,1],\n",
    "    'max_depth' : np.arange(5,10),\n",
    "    'gamma' : np.arange(0,0.3,0.1),\n",
    "    'subsample' : np.arange(0.5,1,0.1),\n",
    "}, cv = 3, return_train_score = False, n_jobs = -1, verbose=10)\n",
    "#model = xgb.XGBRegressor(objective = 'reg:logistic', n_estimators = 450, alpha = 0.001, colsample_bytree = 0.4,learning_rate = 0.02,\n",
    "#                         max_depth = 7, subsample = 0.6)\n",
    "model.fit(division_x_train, division_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos los resultados del CrossValidation\n",
    "\n",
    "df = pd.DataFrame(model.cv_results_)\n",
    "df_reducido = df.loc[:,['params','mean_test_score']]\n",
    "df_reducido.nlargest(5,'mean_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Luego del CrossValidation entrenamos el algoritmo y vemos su error\n",
    "\n",
    "predictions = model.predict(division_x_test)\n",
    "error = np.sqrt(mean_squared_error(division_y_test, predictions))\n",
    "\n",
    "print (\"Error final del algoritmo entrenado con los últimos parametros = \" + str(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos que parametros son los que mejores resultados dieron para luego aplicarlos en el XGBoost que predice.\n",
    "\n",
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(division_y_test, model.predict(division_x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(division_y_test, model.predict(division_x_test).round())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
