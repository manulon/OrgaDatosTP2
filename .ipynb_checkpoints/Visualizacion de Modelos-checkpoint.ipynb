{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-42599386c3c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneural_network\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneural_network\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMLPRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pasamos Los Features del otro notebook\n",
    "\n",
    "oportunidades = pd.read_csv(\"Train_TP2_Datos_2020-2C.csv\")\n",
    "oportunidades['Account_Created_Date'] = pd.to_datetime(oportunidades['Account_Created_Date'])\n",
    "oportunidades['Opportunity_Created_Date'] = pd.to_datetime(oportunidades['Opportunity_Created_Date'])\n",
    "oportunidades['Quote_Expiry_Date'] = pd.to_datetime(oportunidades['Quote_Expiry_Date'])\n",
    "oportunidades['Last_Modified_Date'] = pd.to_datetime(oportunidades['Last_Modified_Date'])\n",
    "oportunidades['Planned_Delivery_Start_Date'] = pd.to_datetime(oportunidades['Planned_Delivery_Start_Date'])\n",
    "oportunidades['Planned_Delivery_End_Date'] = pd.to_datetime(oportunidades['Planned_Delivery_End_Date'])\n",
    "oportunidades_japon = (oportunidades.loc[oportunidades['Region'] == 'Japan'])\n",
    "oportunidades = (oportunidades.loc[oportunidades['Region'] != 'Japan'])\n",
    "#oportunidades_japon = oportunidades_japon.iloc[:,:3]\n",
    "oportunidades_japon['Territory'] = oportunidades_japon['Territory'].replace({'None':'Japan'})\n",
    "oportunidades = pd.concat([oportunidades, oportunidades_japon], axis=0)\n",
    "oportunidades['Region'] = oportunidades['Region'].replace({'Japan':'APAC', 'Middle East':'EMEA'})\n",
    "oportunidades[oportunidades.select_dtypes(['object']).columns] = oportunidades.select_dtypes(['object']).apply(lambda x: x.astype('category'))\n",
    "oportunidades = oportunidades.loc[oportunidades['Territory'] != 'None']\n",
    "oportunidades = oportunidades.dropna()\n",
    "\n",
    "filtro_terminos_entrega = oportunidades['Pricing, Delivery_Terms_Quote_Appr']\\\n",
    "     == oportunidades['Pricing, Delivery_Terms_Approved']\n",
    "\n",
    "filtro_codigo_burocratico = oportunidades['Bureaucratic_Code_0_Approval']\\\n",
    "     == oportunidades['Bureaucratic_Code_0_Approved']\n",
    "\n",
    "oportunidades = oportunidades.drop(['Pricing, Delivery_Terms_Quote_Appr'\\\n",
    "    ,'Pricing, Delivery_Terms_Approved', 'Bureaucratic_Code_0_Approval'\\\n",
    "        , 'Bureaucratic_Code_0_Approved', 'Submitted_for_Approval'], axis = 'columns')\n",
    "\n",
    "oportunidades_posibles = (filtro_terminos_entrega & filtro_codigo_burocratico)\n",
    "\n",
    "oportunidades.insert(3,'Es_Oportunidad_Posible', oportunidades_posibles)\n",
    "\n",
    "oportunidades['Es_Oportunidad_Posible'] = oportunidades['Es_Oportunidad_Posible'].replace(\n",
    "    {True:1, False:0})\n",
    "oportunidades.head()\n",
    "\n",
    "encoding_owners = oportunidades.groupby('Opportunity_Owner').agg({'Total_Amount':'mean'})\n",
    "encoding_owners.columns = ['Encoding_Vendedor']\n",
    "encoding_owners = encoding_owners.reset_index()\n",
    "oportunidades = oportunidades.merge(encoding_owners, how='inner', on='Opportunity_Owner')\n",
    "\n",
    "encoding_territory = oportunidades.groupby('Territory').agg({'Total_Amount' : 'mean'})\n",
    "encoding_territory.columns = ['Encoding_Territorio']\n",
    "encoding_territory = encoding_territory.reset_index()\n",
    "oportunidades = oportunidades.merge(encoding_territory, how='inner', on='Territory')\n",
    "\n",
    "oportunidades = pd.concat([oportunidades, pd.get_dummies(oportunidades['Region'])],axis='columns')\n",
    "\n",
    "encoding_moneda = oportunidades.groupby('Total_Amount_Currency').agg({'ASP' : 'mean'})\n",
    "encoding_moneda.columns = ['Encoding_Moneda']\n",
    "encoding_moneda = encoding_moneda.reset_index()\n",
    "oportunidades = oportunidades.merge(encoding_moneda, how='inner', on='Total_Amount_Currency')\n",
    "\n",
    "oportunidades = pd.concat([oportunidades, pd.get_dummies(oportunidades['Bureaucratic_Code'])], axis='columns')\n",
    "\n",
    "encoding_bill_c = oportunidades.groupby('Billing_Country').agg({'Total_Amount' : 'mean'})\n",
    "encoding_bill_c.columns = ['Encoding_Billing_Country']\n",
    "encoding_bill_c = encoding_bill_c.reset_index()\n",
    "oportunidades = oportunidades.merge(encoding_bill_c, how='inner', on='Billing_Country')\n",
    "\n",
    "encoding_product_family = oportunidades.groupby('Product_Family').agg({'Total_Amount' : 'mean'})\n",
    "encoding_product_family.columns = ['Encoding_Prod_Family']\n",
    "encoding_product_family = encoding_product_family.reset_index()\n",
    "oportunidades = oportunidades.merge(encoding_product_family, how='inner', on='Product_Family')\n",
    "\n",
    "oportunidades = pd.concat([oportunidades, pd.get_dummies(oportunidades['Account_Type'])],axis='columns')\n",
    "\n",
    "encoding_account_name = oportunidades.groupby('Account_Name').agg({'Total_Amount' : 'mean'})\n",
    "encoding_account_name.columns = ['Encoding_Acc_Name']\n",
    "encoding_account_name = encoding_account_name.reset_index()\n",
    "oportunidades = oportunidades.merge(encoding_account_name, how='inner', on='Account_Name')\n",
    "\n",
    "oportunidades = pd.concat([oportunidades,pd.get_dummies(oportunidades['Delivery_Terms'])],axis='columns')\n",
    "\n",
    "oportunidades['Opportunity_Created_Year'] = oportunidades['Opportunity_Created_Date'].dt.year\n",
    "oportunidades['Opportunity_Created_Month'] = oportunidades['Opportunity_Created_Date'].dt.month\n",
    "\n",
    "encoding_op_type = oportunidades.groupby('Opportunity_Type').agg({'Total_Taxable_Amount' : 'mean'})\n",
    "encoding_op_type.columns = ['Encoding_Opportunity_Type']\n",
    "encoding_op_type = encoding_op_type.reset_index()\n",
    "oportunidades = oportunidades.merge(encoding_op_type, how='inner', on='Opportunity_Type')\n",
    "\n",
    "oportunidades = pd.concat([oportunidades, pd.get_dummies(oportunidades['Source '])],axis = 'columns')\n",
    "\n",
    "y_train = oportunidades['Stage']\n",
    "oportunidades = oportunidades.loc[(oportunidades['Stage'] == 'Closed Won') | (oportunidades['Stage'] == 'Closed Lost')]\n",
    "oportunidades['Stage'] = oportunidades['Stage'].replace({'Closed Won': 1, 'Closed Lost': 0})\n",
    "std_deviation_amounts = oportunidades.groupby('Opportunity_ID').agg({'TRF':'std', 'Opportunity_Created_Month':'std'})\n",
    "std_deviation_amounts.columns = ['TRF_Std', 'Opp_Created_Month_Std']\n",
    "std_deviation_amounts = std_deviation_amounts.reset_index()\n",
    "\n",
    "#Solo usamos Bureau_Code_ 0,1,2,4,5 porque son los que tiene el set de test.\n",
    "x_train = oportunidades.groupby('Opportunity_ID').agg({'Opportunity_Created_Year' : 'mean',\\\n",
    "                                                       'Opportunity_Created_Month' : 'mean',\\\n",
    "                                                      'Encoding_Moneda':'mean', 'Total_Amount': 'sum',\\\n",
    "                                                      'Total_Taxable_Amount':'sum',\\\n",
    "                                                      'Encoding_Territorio':'mean','Encoding_Vendedor':'mean',\\\n",
    "                                                      'Es_Oportunidad_Posible':'mean','Stage':'max', 'TRF':'mean',\n",
    "                                                      'Bureaucratic_Code_0':'mean','Bureaucratic_Code_1':'mean',\\\n",
    "                                                      'Bureaucratic_Code_2':'mean','Bureaucratic_Code_4':'mean',\n",
    "                                                      'Bureaucratic_Code_5':'mean', 'Encoding_Billing_Country':'mean',\\\n",
    "                                                      'Delivery_Terms_0':'mean','Delivery_Terms_1':'mean','Delivery_Terms_2':'mean',\\\n",
    "                                                      'Delivery_Terms_3':'mean','Delivery_Terms_4':'mean','Delivery_Terms_5':'mean',\\\n",
    "                                                      'Delivery_Terms_6':'mean','Delivery_Terms_7':'mean','Delivery_Terms_8':'mean',\n",
    "                                                      'Encoding_Prod_Family':'mean','Account_Type_0':'mean','Account_Type_1':'mean',\\\n",
    "                                                      'Account_Type_2':'mean','Account_Type_4':'mean', 'Account_Type_5':'mean',\\\n",
    "                                                      'APAC' : 'mean','Americas':'mean','EMEA':'mean', 'Encoding_Acc_Name':'mean',\\\n",
    "                                                      'Encoding_Opportunity_Type':'mean', 'Source_3':'mean', 'Source_7':'mean',\\\n",
    "                                                      'Source_9':'mean','Source_11':'mean','Source_13':'mean'})\n",
    "x_train = x_train.reset_index()\n",
    "x_train = x_train.merge(std_deviation_amounts, on='Opportunity_ID', how='inner')\n",
    "x_train = x_train.set_index('Opportunity_ID')\n",
    "y_train = x_train['Stage']\n",
    "x_train = x_train.drop('Stage', axis='columns')\n",
    "x_train['TRF_Std'] = x_train['TRF_Std'].replace({np.nan:0})\n",
    "x_train['Opp_Created_Month_Std'] = x_train['Opp_Created_Month_Std'].replace({np.nan:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos los modelos de XGBoost y CatBoost\n",
    "\n",
    "model_xgb = xgb.XGBClassifier()\n",
    "model_catb = CatBoostClassifier()\n",
    "model_mlp = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividimos el set en train y test, y entrenamos ambos modelos\n",
    "\n",
    "division_x_train, division_x_test, division_y_train, division_y_test = train_test_split(x_train, y_train, test_size = 0.3,\\\n",
    "                                                                                       random_state = 123)\n",
    "model_xgb.fit(division_x_train, division_y_train)\n",
    "model_catb.fit(division_x_train, division_y_train)\n",
    "model_mlp.fit(division_x_train, division_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scoreamos con XGBoost\n",
    "model_xgb.score(division_x_test, division_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scoreamos con CatBoost\n",
    "model_catb.score(division_x_test, division_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scoreamos con Perceptron\n",
    "model_mlp.score(division_x_test, division_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn = Sequential()\n",
    "model_nn.add(Input(shape=(X_train.shape[1],)))\n",
    "model_nn.add(Dense(64, activation='relu'))\n",
    "model_nn.add(Dropout(0.2))\n",
    "model_nn.add(Dense(16, activation='relu')) \n",
    "model_nn.add(Dropout(0.1))\n",
    "model_nn.add(Dense(1, activation='sigmoid'))\n",
    "model_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) # adadelta\n",
    "model_nn.fit(X_train, y_train, epochs=10, batch_size=16)\n",
    "results = model_nn.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn = get_compiled_model()\n",
    "model_nn.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
