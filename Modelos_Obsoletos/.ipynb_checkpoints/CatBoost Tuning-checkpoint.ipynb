{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pasamos Los Features del otro notebook\n",
    "#Encoding para el dataset de testeo, con los mismos que en training set.\n",
    "\n",
    "encoding_owners = oportunidades.groupby('Opportunity_Owner').agg({'Total_Amount':'mean'})\n",
    "encoding_owners.columns = ['Encoding_Vendedor']\n",
    "encoding_owners = encoding_owners.reset_index()\n",
    "oportunidades = oportunidades.merge(encoding_owners, how='inner', on='Opportunity_Owner')\n",
    "\n",
    "encoding_territory = oportunidades.groupby('Territory').agg({'Total_Amount' : 'mean'})\n",
    "encoding_territory.columns = ['Encoding_Territorio']\n",
    "encoding_territory = encoding_territory.reset_index()\n",
    "oportunidades = oportunidades.merge(encoding_territory, how='inner', on='Territory')\n",
    "\n",
    "encoding_region = oportunidades.groupby('Region').agg({'Total_Amount' : 'mean'})\n",
    "encoding_region.columns = ['Encoding_Region']\n",
    "encoding_region = encoding_region.reset_index()\n",
    "oportunidades = oportunidades.merge(encoding_region, how='inner', on='Region')\n",
    "\n",
    "encoding_moneda = oportunidades.groupby('Total_Amount_Currency').agg({'Moneda_Convertida' : 'mean'})\n",
    "encoding_moneda.columns = ['Encoding_Moneda']\n",
    "encoding_moneda = encoding_moneda.reset_index()\n",
    "oportunidades = oportunidades.merge(encoding_moneda, how='inner', on='Total_Amount_Currency')\n",
    "oportunidades\n",
    "\n",
    "oportunidades = pd.concat([oportunidades, pd.get_dummies(oportunidades['Bureaucratic_Code'])],axis='columns')\n",
    "\n",
    "encoding_bill_c = oportunidades.groupby('Billing_Country').agg({'Total_Amount' : 'mean'})\n",
    "encoding_bill_c.columns = ['Encoding_Billing_Country']\n",
    "encoding_bill_c = encoding_bill_c.reset_index()\n",
    "oportunidades = oportunidades.merge(encoding_bill_c, how='inner', on='Billing_Country')\n",
    "oportunidades\n",
    "\n",
    "oportunidades = pd.concat([oportunidades, pd.get_dummies(oportunidades['Account_Type'])],axis='columns')\n",
    "\n",
    "oportunidades = pd.concat([oportunidades,pd.get_dummies(oportunidades['Delivery_Terms'])],axis='columns')\n",
    "\n",
    "encoding_product_family = oportunidades.groupby('Product_Family').agg({'Total_Amount' : 'mean'})\n",
    "encoding_product_family.columns = ['Encoding_Prod_Family']\n",
    "encoding_product_family = encoding_product_family.reset_index()\n",
    "oportunidades = oportunidades.merge(encoding_product_family, how='inner', on='Product_Family')\n",
    "\n",
    "oportunidades['Opportunity_Created_Year'] = oportunidades['Opportunity_Created_Date'].dt.year\n",
    "oportunidades['Opportunity_Created_Month'] = oportunidades['Opportunity_Created_Date'].dt.month\n",
    "oportunidades['Año_Por_Mes'] = oportunidades['Opportunity_Created_Year'] * oportunidades['Opportunity_Created_Month']\n",
    "\n",
    "y_train = oportunidades['Stage']\n",
    "oportunidades = oportunidades.loc[(oportunidades['Stage'] == 'Closed Won') | (oportunidades['Stage'] == 'Closed Lost')]\n",
    "oportunidades['Stage'] = oportunidades['Stage'].replace({'Closed Won': 1, 'Closed Lost': 0})\n",
    "std_deviation_amounts = oportunidades.groupby('Opportunity_ID').agg({'TRF':'std', 'Opportunity_Created_Month':'std'})\n",
    "std_deviation_amounts.columns = ['TRF_Std', 'Opp_Created_Month_Std']\n",
    "std_deviation_amounts = std_deviation_amounts.reset_index()\n",
    "\n",
    "#Solo usamos Bureau_Code_ 0,1,2,4,5 porque son los que tiene el set de test.\n",
    "#Hacemos el groupby\n",
    "\n",
    "# std_deviation_amounts = oportunidades.groupby('Opportunity_ID').agg({'TRF':'std'})\n",
    "# std_deviation_amounts.columns = ['TRF_Std']\n",
    "# std_deviation_amounts = std_deviation_amounts.reset_index()\n",
    "x_train = oportunidades.groupby('Opportunity_ID').agg({'Año_Por_Mes' : 'mean',\\\n",
    "                                                      'Encoding_Moneda':'mean', 'Total_Amount': 'sum',\\\n",
    "                                                      'Total_Taxable_Amount':'mean', 'Encoding_Region':'mean',\\\n",
    "                                                      'Encoding_Territorio':'mean','Encoding_Vendedor':'mean',\\\n",
    "                                                      'Es_Oportunidad_Posible':'mean', 'Bureaucratic_Code_0':'mean',\\\n",
    "                                                     'Bureaucratic_Code_1':'mean','Bureaucratic_Code_2':'mean','Bureaucratic_Code_4':'mean',\\\n",
    "                                                     'Bureaucratic_Code_5':'mean', 'Encoding_Billing_Country':'mean',\\\n",
    "                                                      'Delivery_Terms_0':'mean','Delivery_Terms_1':'mean','Delivery_Terms_2':'mean',\\\n",
    "                                                      'Delivery_Terms_3':'mean','Delivery_Terms_4':'mean','Delivery_Terms_5':'mean',\\\n",
    "                                                      'Delivery_Terms_6':'mean','Delivery_Terms_7':'mean','Delivery_Terms_8':'mean',\n",
    "                                                     'Encoding_Prod_Family':'mean','Account_Type_0':'mean','Account_Type_1':'mean',\\\n",
    "                                                      'Account_Type_2':'mean','Account_Type_4':'mean', 'Account_Type_5':'mean'})\n",
    "x_train = x_train.reset_index()\n",
    "#x_test = x_test.merge(std_deviation_amounts, on='Opportunity_ID', how='inner')\n",
    "x_train = x_train.set_index('Opportunity_ID')\n",
    "#x_test['Total_Amount_Std'] = x_test['Total_Amount_Std'].replace({np.nan:0})\n",
    "#x_test['Total_Tax_Amount_Std'] = x_test['Total_Tax_Amount_Std'].replace({np.nan:0})\n",
    "x_train['Total_Amount'] = (x_train['Total_Amount'] / x_train['Encoding_Moneda']) \n",
    "x_train['Total_Taxable_Amount'] = (x_train['Total_Taxable_Amount'] / x_train['Encoding_Moneda']) \n",
    "x_train['Diferencia_Amounts'] = (x_train['Total_Amount'] - x_train['Total_Taxable_Amount'])\n",
    "x_train = x_train.drop(['Encoding_Moneda'], axis='columns')\n",
    "#x_test['TRF_Std'] = x_test['TRF_Std'].replace({np.nan:0})\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Division del set de test y train:\n",
    "\n",
    "division_x_train, division_x_test, division_y_train, division_y_test = train_test_split(x_train, y_train, test_size = 0.3,\\\n",
    "                                                                                       random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10500 candidates, totalling 21000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    8.3s\n",
      "exception calling callback for <Future at 0x210bbb36fd0 state=finished raised TerminatedWorkerError>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 347, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 780, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 531, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\reusable_executor.py\", line 177, in submit\n",
      "    return super(_ReusablePoolExecutor, self).submit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 1102, in submit\n",
      "    raise self._flags.broken\n",
      "joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tuning de Hiper parametros con GridSearchCV\n",
    "\n",
    "model = RandomizedSearchCV(CatBoostRegressor({\n",
    "    'iterations' : [100,200,300,400,500],\n",
    "    'learning_rate' : np.arange(0.01, 0.1, 0.01),\n",
    "    'border_count' : [4,5,6,7,8,9,10],\n",
    "    #'colsample_bytree' : np.arange(0.3,0.8,0.1),\n",
    "    #'alpha' : [0.0001,0.001,0.01],\n",
    "    'depth' : np.arange(5,11),\n",
    "    'l2_leaf_reg' : np.logspace(-20, 0),\n",
    "    #'gamma' : np.arange(0,0.3,0.05),\n",
    "    'random_strength' : np.arange(0.5,1,0.1),\n",
    "}, cv = 3, return_train_score = False, n_jobs = -1, verbose=10, n_iter=700)\n",
    "\n",
    "model.fit(division_x_train, division_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(division_x_test, division_y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
